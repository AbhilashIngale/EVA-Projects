{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session4_First DNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhilashIngale/EVA-Projects/blob/master/Session_4/Session4_First_DNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# Session 4 : Train MNIST  with a custom Neural Network achieving 99.4% accuracy ( keeping parameter count below 15k )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLknLcKDm6Mc",
        "colab_type": "text"
      },
      "source": [
        "#  Iteration 1\n",
        "## AIM :  In  this iteration, the aim is to get to the parameter count well-within the range and evaluate the network for a small batch size for 20 epochs.\n",
        "## Instead of targeting to achieve the required test accuracy in this iteration, we would just be evaluating if the accuracy is steadily increasing or settling by the end of 20th epoch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHine6kImUaJ",
        "colab_type": "text"
      },
      "source": [
        "##Import Libraries and modules##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "81cab6b4-c56d-4bb2-b811-108095f18215"
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the dependancies and packages required\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# Import the MNIST dataset from keras\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "## Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Doing the train-test split on the MNIST dataset. Default split ratio (test to train ) is : 1:6\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "221c3c5c-2f6e-4178-c8a4-5206d57fbd78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# Visualizing one of the images from the training set\n",
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[500])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f099ab51fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting the intensity range from 0-255 to 0-1 . This is done basically to avoid high computations and preserve system memory.\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "a5efd5e1-16c5-4428-b052-4bda1a3b7e59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Print the true labels in the training set.\n",
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "0b5f3f64-e29a-4580-867b-86b056f2aed6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "# Print the class matrix of the training set. Here, the true label is the one where '1' occurs for each training point.\n",
        "Y_train[:10]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKyp5sR2XLsZ",
        "colab_type": "text"
      },
      "source": [
        "##Network Architecture : Iteration 1- Vanilla Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "137351b7-004d-425d-889f-5b79909a58d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "# Importing Activation function \n",
        "from keras.layers import Activation\n",
        "   \n",
        "############################ START #############################################\n",
        "\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Convolution2D(12, 3, 3,activation='relu', input_shape=(28,28,1))) #26    \n",
        "model.add(Convolution2D(24, 3, 3,activation='relu')) #24                            \n",
        "\n",
        "model.add(Convolution2D(12, 1, 1, activation='relu')) #24                            \n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) #12                                      \n",
        "\n",
        "model.add(Convolution2D(12, 3, 3, activation='relu')) # 10                           \n",
        "\n",
        "model.add(Convolution2D(18, 3, 3, activation='relu')) # 8                          \n",
        "\n",
        "model.add(Convolution2D(24, 3, 3, activation='relu')) # 6                         \n",
        "\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu')) # 6                                  \n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))  # 3                                    \n",
        "                                                       \n",
        "model.add(Convolution2D(10, 3, 3, activation= None )) #1                            \n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "############################## END #############################################"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (1, 1), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(18, (3, 3), activation=\"relu\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=None)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciRt6E5i8fY1",
        "colab_type": "code",
        "outputId": "e122a51e-bdcf-43bf-acd2-843e9b43e9b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        }
      },
      "source": [
        "# Shows the image shape after each convolution and the parameter count. Also, shows the trainable and non-trainable parameters. \n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_73 (Conv2D)           (None, 26, 26, 12)        120       \n",
            "_________________________________________________________________\n",
            "conv2d_74 (Conv2D)           (None, 24, 24, 24)        2616      \n",
            "_________________________________________________________________\n",
            "conv2d_75 (Conv2D)           (None, 24, 24, 12)        300       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 12, 12, 12)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_76 (Conv2D)           (None, 10, 10, 12)        1308      \n",
            "_________________________________________________________________\n",
            "conv2d_77 (Conv2D)           (None, 8, 8, 18)          1962      \n",
            "_________________________________________________________________\n",
            "conv2d_78 (Conv2D)           (None, 6, 6, 24)          3912      \n",
            "_________________________________________________________________\n",
            "conv2d_79 (Conv2D)           (None, 6, 6, 10)          250       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 3, 3, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_80 (Conv2D)           (None, 1, 1, 10)          910       \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 11,378\n",
            "Trainable params: 11,378\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model: Specify loss function , optimizer e.g. SGD , adam etc.(in optimizer set learning rate which is a hyper-parameter)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab_type": "code",
        "outputId": "e19eb546-76f6-44ca-c86d-329d3ef3a589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        }
      },
      "source": [
        "# FIT \n",
        "model.fit(X_train, Y_train, batch_size=20, nb_epoch=20, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 22s 366us/step - loss: 0.2323 - acc: 0.9278\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 19s 318us/step - loss: 0.0792 - acc: 0.9753\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 19s 318us/step - loss: 0.0580 - acc: 0.9819\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 19s 323us/step - loss: 0.0486 - acc: 0.9843\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 20s 337us/step - loss: 0.0422 - acc: 0.9871\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 20s 331us/step - loss: 0.0390 - acc: 0.9876\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 19s 318us/step - loss: 0.0335 - acc: 0.9891\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 19s 321us/step - loss: 0.0305 - acc: 0.9901\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 20s 338us/step - loss: 0.0296 - acc: 0.9905\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 19s 321us/step - loss: 0.0264 - acc: 0.9913\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 19s 320us/step - loss: 0.0246 - acc: 0.9923\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 20s 331us/step - loss: 0.0222 - acc: 0.9926\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 20s 341us/step - loss: 0.0218 - acc: 0.9927\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 20s 325us/step - loss: 0.0207 - acc: 0.9933\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 19s 324us/step - loss: 0.0193 - acc: 0.9936\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 20s 336us/step - loss: 0.0178 - acc: 0.9941\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 21s 349us/step - loss: 0.0168 - acc: 0.9943\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 19s 320us/step - loss: 0.0170 - acc: 0.9939\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 19s 317us/step - loss: 0.0150 - acc: 0.9947\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 19s 325us/step - loss: 0.0153 - acc: 0.9946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f03631ce6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Making predictions on the test set and storing the result y_pred\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYkC_go_ZSDs",
        "colab_type": "code",
        "outputId": "8826b49e-3d4b-47e2-e5e9-d75404a22bc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Evaluates the metrics i.e. Loss and Accuracy on the test set\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "# Printing the metrics evaluated above\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.03526806984773502, 0.9901]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-TD3QNIEWIw",
        "colab_type": "text"
      },
      "source": [
        "## Observation\n",
        "### As we can see, the model architecture has a lesser parameter count now and we would not be working on changing the number of parameters. Also, we have already started to reach very close to the desired test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab_type": "code",
        "outputId": "da33a854-c2d5-4bb6-f1e6-9099cd3e6436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        }
      },
      "source": [
        "# print the predicted class matrix and true test labels.\n",
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.31389130e-16 1.48945540e-13 4.99052248e-06 6.33824513e-08\n",
            "  5.82705339e-14 2.63873972e-15 2.74861038e-23 9.99994993e-01\n",
            "  1.68056419e-11 2.15616254e-08]\n",
            " [6.05314696e-08 1.21700708e-07 9.99999523e-01 2.08961841e-12\n",
            "  7.14140214e-08 1.41766275e-12 1.44740270e-07 7.67749918e-14\n",
            "  1.43396753e-10 8.98067102e-13]\n",
            " [1.91811581e-10 9.99996543e-01 5.97800476e-10 4.48272530e-11\n",
            "  1.25790356e-08 1.48834767e-09 3.08686604e-10 3.38686300e-06\n",
            "  2.81205637e-09 2.38581821e-10]\n",
            " [9.99999762e-01 7.18704082e-20 1.03585494e-10 5.09534645e-12\n",
            "  6.21568701e-14 2.07460837e-11 2.35638609e-07 8.67529874e-16\n",
            "  3.01699927e-08 2.47757065e-10]\n",
            " [1.18515328e-16 2.33428242e-11 2.66843020e-10 1.15359071e-16\n",
            "  9.99996662e-01 1.69293299e-16 1.40632601e-12 3.55199030e-11\n",
            "  1.39765866e-09 3.35715276e-06]\n",
            " [5.55389170e-14 9.99997973e-01 3.45013323e-11 1.41774982e-12\n",
            "  2.99277367e-08 9.36279596e-11 1.48818273e-12 1.99573810e-06\n",
            "  1.67007977e-10 1.57093738e-09]\n",
            " [9.09935647e-27 4.08409057e-10 5.07098183e-12 9.07663036e-16\n",
            "  9.99999762e-01 1.20758154e-18 4.65359494e-21 2.09635488e-07\n",
            "  1.38658807e-09 7.34163230e-10]\n",
            " [9.18791779e-12 2.38144465e-13 8.98312624e-09 3.43470391e-11\n",
            "  2.33801423e-08 3.74430955e-13 1.93279816e-17 5.56199198e-10\n",
            "  1.35053924e-09 1.00000000e+00]\n",
            " [2.33200545e-17 6.91130313e-17 1.18846335e-15 2.19540559e-13\n",
            "  1.84395913e-17 9.95668650e-01 4.33053402e-03 6.65417818e-15\n",
            "  8.20705736e-07 4.51118038e-13]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT--y98_dr2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GY4Upv4dsUR",
        "colab_type": "code",
        "outputId": "8ef36c14-748a-4209-cfcd-54b72193f246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "source": [
        "################# CODE TO VISUALIZE FEATURE MAPS ###############################\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'conv2d_65'):\n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    else:\n",
        "        plot_x, plot_y = 1, 2\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0, 0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-166-f76d59b59343>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'filter %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mplot_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mvis_img_in_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-166-f76d59b59343>\u001b[0m in \u001b[0;36mvis_img_in_filter\u001b[0;34m(img, layer_name)\u001b[0m\n\u001b[1;32m     22\u001b[0m def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n\u001b[1;32m     23\u001b[0m                       layer_name = 'conv2d_65'):\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mimg_ascs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilter_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'conv2d_65'"
          ]
        }
      ]
    }
  ]
}